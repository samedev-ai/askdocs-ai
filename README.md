<<<<<<< HEAD
# ğŸ“š Document Upload and QA System

> **An AI-powered document analysis system that extracts insights from your PDF documents using advanced language models.**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.0%2B-red.svg)](https://streamlit.io)
[![OpenRouter](https://img.shields.io/badge/OpenRouter-API-green.svg)](https://openrouter.ai)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸš€ Quick Start

<details>
<summary><strong>ğŸ¯ Click to expand Quick Start Guide</strong></summary>

### 1. Clone & Setup
```bash
git clone <your-repo-url>
cd python
pip install -r requirements.txt
```

### 2. Set up API Key
Choose one of these methods:

**Option A: Environment Variable**
```bash
export OPENROUTER_API_KEY="your-api-key-here"
```

**Option B: Streamlit Secrets (Recommended)**
```bash
mkdir .streamlit
echo 'OPENROUTER_API_KEY = "your-api-key-here"' > .streamlit/secrets.toml
```

### 3. Run the Application
```bash
streamlit run app.py
```

### 4. Open in Browser
Navigate to `http://localhost:8501` and start uploading documents!

</details>

## âœ¨ Features

<details>
<summary><strong>ğŸ”¥ Core Features</strong></summary>

- **ğŸ“„ PDF Upload & Processing** - Drag and drop any PDF document
- **ğŸ§  AI-Powered Q&A** - Ask questions in natural language
- **ğŸ” Semantic Search** - Find relevant information using embeddings
- **ğŸ“‹ Smart Summarization** - Get comprehensive document summaries
- **ğŸ’¾ Persistent Storage** - Documents are indexed and stored locally
- **ğŸ¨ Interactive UI** - Clean, user-friendly Streamlit interface
- **ğŸ“± Responsive Design** - Works on desktop and mobile

</details>

<details>
<summary><strong>ğŸ¤– AI Models Used</strong></summary>

- **Embedding Model**: `sentence-transformers/all-MiniLM-L6-v2`
- **Question Answering**: `mistralai/mistral-7b-instruct`
- **Summarization**: `meta/llama-2-70b-chat`

</details>

## ğŸ—ï¸ Project Structure

<details>
<summary><strong>ğŸ“ Click to view project structure</strong></summary>

```
python/
â”œâ”€â”€ ğŸ“± app.py              # Main Streamlit application
â”œâ”€â”€ ğŸ”§ main.py             # Command-line interface
â”œâ”€â”€ âš™ï¸ config.py           # API configuration
â”œâ”€â”€ ğŸ“‹ requirements.txt    # Dependencies
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ Core Modules:
â”‚   â”œâ”€â”€ ğŸ“¤ upload.py       # File upload handling
â”‚   â”œâ”€â”€ ğŸ“– extract_text.py # PDF text extraction
â”‚   â”œâ”€â”€ ğŸ§  embed_documents.py # Document embedding & search
â”‚   â””â”€â”€ ğŸ’¬ qa_pipeline.py  # Question answering pipeline
â”œâ”€â”€ 
â”œâ”€â”€ ğŸ“‚ Storage:
â”‚   â”œâ”€â”€ ğŸ“ uploaded_docs/  # Uploaded PDF files
â”‚   â””â”€â”€ ğŸ’¾ document_store.pkl # Indexed documents & embeddings
â””â”€â”€ 
â””â”€â”€ ğŸ“‚ Cache:
    â””â”€â”€ ğŸ—‚ï¸ __pycache__/     # Python cache files
```

</details>

## ğŸ¯ How It Works

<details>
<summary><strong>ğŸ”„ Click to understand the workflow</strong></summary>

### Step-by-Step Process:

1. **ğŸ“¤ Upload**: User uploads a PDF document through the web interface
2. **ğŸ” Extract**: System extracts text from the PDF using PyMuPDF
3. **âœ‚ï¸ Chunk**: Text is split into meaningful paragraphs
4. **ğŸ§  Embed**: Each paragraph is converted to vector embeddings
5. **ğŸ’¾ Store**: Documents and embeddings are stored locally
6. **â“ Query**: User asks a question about the document
7. **ğŸ” Search**: System finds most relevant paragraphs using similarity search
8. **ğŸ¤– Generate**: AI model generates an answer based on relevant context
9. **ğŸ“‹ Display**: Answer is presented with copy/clear options

</details>

## ğŸ› ï¸ Installation & Setup

<details>
<summary><strong>ğŸ”§ Detailed Installation Guide</strong></summary>

### Prerequisites
- Python 3.8 or higher
- pip package manager
- OpenRouter API key ([Get one here](https://openrouter.ai))

### Step 1: Environment Setup
```bash
# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 3: API Configuration
Create your API key configuration:

**Method 1: Environment Variable**
```bash
# Windows
set OPENROUTER_API_KEY=your-api-key-here

# macOS/Linux
export OPENROUTER_API_KEY=your-api-key-here
```

**Method 2: Streamlit Secrets (Recommended for deployment)**
```bash
mkdir .streamlit
cat > .streamlit/secrets.toml << EOF
OPENROUTER_API_KEY = "your-api-key-here"
EOF
```

### Step 4: Test Installation
```bash
# Test with command line interface
python main.py

# Or run the web app
streamlit run app.py
```

</details>

## ğŸ“– Usage Examples

<details>
<summary><strong>ğŸ’¡ Example Questions & Use Cases</strong></summary>

### ğŸ“Š Document Analysis
```
â€¢ "Summarize this document"
â€¢ "What are the main points?"
â€¢ "What is this document about?"
â€¢ "What are the key findings?"
```

### ğŸ” Specific Information
```
â€¢ "What are the conclusions?"
â€¢ "Are there any recommendations?"
â€¢ "What methodology was used?"
â€¢ "What are the limitations mentioned?"
```

### ğŸ“ˆ Data Extraction
```
â€¢ "What statistics are mentioned?"
â€¢ "Are there any dates or deadlines?"
â€¢ "What companies are mentioned?"
â€¢ "What are the financial figures?"
```

### ğŸ¯ Research Questions
```
â€¢ "What evidence supports the main argument?"
â€¢ "What are the counterarguments?"
â€¢ "What future research is suggested?"
â€¢ "What are the practical implications?"
```

</details>

## ğŸ”§ Configuration

<details>
<summary><strong>âš™ï¸ Advanced Configuration Options</strong></summary>

### Model Configuration
You can modify the models used in `qa_pipeline.py`:

```python
# For regular questions (faster, cheaper)
model = "mistralai/mistral-7b-instruct"

# For summarization (better quality)
model = "meta/llama-2-70b-chat"

# Alternative models you can try:
# "anthropic/claude-3-haiku"
# "openai/gpt-3.5-turbo"
# "google/gemini-pro"
```

### Search Configuration
Adjust search parameters in `embed_documents.py`:

```python
# Number of similar paragraphs to retrieve
top_k = 3  # Default for questions
top_k = 10  # Default for summarization

# Embedding model (can be changed)
embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
```

### Upload Configuration
Modify upload settings in `upload.py`:

```python
UPLOAD_DIR = "uploaded_docs"  # Change upload directory
# Add file size limits, allowed types, etc.
```

</details>

## ğŸ› Troubleshooting

<details>
<summary><strong>ğŸ” Common Issues & Solutions</strong></summary>

### âŒ API Key Issues
```bash
# Problem: "API key not found"
# Solution: Verify your API key is set correctly
echo $OPENROUTER_API_KEY  # Should show your key
```

### âŒ Module Import Errors
```bash
# Problem: "ModuleNotFoundError"
# Solution: Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### âŒ PDF Processing Issues
```bash
# Problem: "Cannot extract text from PDF"
# Solution: Check if PDF is text-based (not scanned image)
# For scanned PDFs, you'd need OCR functionality
```

### âŒ Memory Issues
```bash
# Problem: "Out of memory"
# Solution: Process smaller documents or increase system memory
# Consider chunking large documents differently
```

### âŒ Streamlit Issues
```bash
# Problem: "Port already in use"
# Solution: Run on different port
streamlit run app.py --server.port 8502
```

</details>

## ğŸš€ Advanced Usage

<details>
<summary><strong>ğŸ”¬ Advanced Features & Customization</strong></summary>

### Command Line Interface
For batch processing or automation:

```bash
# Process a document programmatically
python main.py
```

### Custom Embedding Models
You can experiment with different embedding models:

```python
# In embed_documents.py, try:
# 'sentence-transformers/all-mpnet-base-v2'  # Better quality
# 'sentence-transformers/all-MiniLM-L12-v2'  # Balanced
# 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'  # Multilingual
```

### Adding New Document Types
Extend the system to support other formats:

```python
# Add to extract_text.py
def extract_text_from_docx(file_path):
    # Implementation for Word documents
    pass

def extract_text_from_txt(file_path):
    # Implementation for text files
    pass
```

### Custom Prompts
Modify the AI prompts in `qa_pipeline.py`:

```python
# Customize system prompts for different use cases
system_prompt = "You are a legal document analyst..."  # For legal docs
system_prompt = "You are a research paper reviewer..."  # For academic papers
```

</details>

## ğŸ“Š Performance & Scalability

<details>
<summary><strong>âš¡ Performance Optimization Tips</strong></summary>

### ğŸš€ Speed Optimizations
- **Embedding Caching**: Embeddings are cached locally in `document_store.pkl`
- **Model Selection**: Choose faster models for real-time interactions
- **Batch Processing**: Process multiple documents at once

### ğŸ“ˆ Scaling Considerations
- **Vector Databases**: Consider FAISS, Pinecone, or Weaviate for large datasets
- **Cloud Deployment**: Deploy on AWS, GCP, or Azure for scalability
- **Load Balancing**: Use multiple instances for high traffic

### ğŸ’¾ Storage Management
- **Cleanup**: Regularly clean up old documents and embeddings
- **Compression**: Use document compression for large files
- **Database**: Consider PostgreSQL with pgvector for production

</details>

## ğŸ¤ Contributing

<details>
<summary><strong>ğŸ‰ How to Contribute</strong></summary>

We welcome contributions! Here's how you can help:

### ğŸ› Bug Reports
- Use the issue tracker to report bugs
- Include steps to reproduce
- Provide system information

### ğŸ’¡ Feature Requests
- Suggest new features or improvements
- Explain the use case and benefit
- Consider implementation complexity

### ğŸ”§ Code Contributions
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

### ğŸ“ Documentation
- Improve README sections
- Add code comments
- Create tutorials or examples

</details>

## ğŸ“„ License

<details>
<summary><strong>ğŸ“œ MIT License</strong></summary>

```
MIT License

Copyright (c) 2024 Document QA System

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

</details>

## ğŸ”— Links & Resources

<details>
<summary><strong>ğŸ“š Useful Resources</strong></summary>

### ğŸ› ï¸ Technologies Used
- **[Streamlit](https://streamlit.io)** - Web app framework
- **[OpenRouter](https://openrouter.ai)** - AI model API
- **[Sentence Transformers](https://www.sbert.net)** - Embedding models
- **[PyMuPDF](https://pymupdf.readthedocs.io)** - PDF processing
- **[Haystack](https://haystack.deepset.ai)** - NLP framework

### ğŸ“– Documentation
- [Streamlit Documentation](https://docs.streamlit.io)
- [OpenRouter Models](https://openrouter.ai/docs)
- [Sentence Transformers Models](https://www.sbert.net/docs/pretrained_models.html)

### ğŸ“ Learning Resources
- [Building RAG Systems](https://www.deeplearning.ai/short-courses/building-applications-vector-databases/)
- [Streamlit Tutorials](https://docs.streamlit.io/library/get-started/tutorials)
- [Vector Embeddings Guide](https://www.pinecone.io/learn/vector-embeddings/)

</details>

---

<div align="center">

### ğŸ‰ Ready to analyze your documents with AI?

**[â¬†ï¸ Back to Top](#-document-upload-and-qa-system)** | **[ğŸš€ Quick Start](#-quick-start)** | **[ğŸ“– Usage Examples](#-usage-examples)**

---

**Made with â¤ï¸ by the Document QA Team**

*If you find this project helpful, please consider giving it a â­ star!*

</div>

## ğŸ” Interactive Elements

<details>
<summary><strong>ğŸ® Try These Interactive Commands</strong></summary>

### Quick Test Commands
```bash
# Test your setup
python -c "import streamlit, openai, sentence_transformers; print('âœ… All dependencies installed!')"

# Check API key
python -c "import os; print('âœ… API key found!' if os.getenv('OPENROUTER_API_KEY') else 'âŒ API key not found')"

# Launch app
streamlit run app.py --server.headless true --server.port 8501
```

### Sample Questions to Try
Once you upload a document, try these sample questions:

```
ğŸ“Š "Give me a 2-paragraph summary of this document"
ğŸ” "What are the three most important points?"
ğŸ“ˆ "Are there any statistics or numbers mentioned?"
ğŸ¯ "What recommendations does this document make?"
â“ "What questions does this document raise?"
```

</details>

---

*This interactive README was generated to help you get the most out of your Document QA System. Each section is expandable to show detailed information while keeping the main view clean and navigable.*
=======
# askdocs-ai
A Python RAG app to upload documents and get answers via AI
>>>>>>> 78d695f599b162a18fbbe2229019f49f0a378a94
